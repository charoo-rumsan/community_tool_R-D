{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOd3y+9/+XPLGq6duNSBrRY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charoo-rumsan/community_tool_research/blob/main/data_validation_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaf1650f",
        "outputId": "80816623-8962-4172-87b6-c1e70a9ddb94"
      },
      "source": [
        "!pip install phonenumbers"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: phonenumbers in /usr/local/lib/python3.12/dist-packages (9.0.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74dc80ed",
        "outputId": "6a97394c-fa9e-4816-e54b-0d7ce28e0305"
      },
      "source": [
        "!pip install fuzzywuzzy python-Levenshtein"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.12/dist-packages (0.27.1)\n",
            "Requirement already satisfied: Levenshtein==0.27.1 in /usr/local/lib/python3.12/dist-packages (from python-Levenshtein) (0.27.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "2i_Mfh80xUWk"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import re\n",
        "import json\n",
        "import phonenumbers\n",
        "from phonenumbers import geocoder\n",
        "from pathlib import Path\n",
        "from fuzzywuzzy import fuzz\n",
        "from Levenshtein import ratio\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Fuzzy matcher for column classification\n",
        "def normalize_text(s):\n",
        "    \"\"\"Normalize text for matching.\"\"\"\n",
        "    if s is None:\n",
        "        return \"\"\n",
        "    s = str(s)\n",
        "    s = unicodedata.normalize(\"NFKD\", s)\n",
        "    s = s.lower()\n",
        "    s = re.sub(r\"[^0-9A-Za-z\\u0080-\\uFFFF\\s]\", \" \", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def token_jaccard(a, b):\n",
        "    \"\"\"Calculate Jaccard similarity between tokenized strings.\"\"\"\n",
        "    ta = set(a.split())\n",
        "    tb = set(b.split())\n",
        "    if not ta and not tb:\n",
        "        return 0.0\n",
        "    inter = len(ta & tb)\n",
        "    union = len(ta | tb)\n",
        "    return 0.0 if union == 0 else (inter / union) * 100.0\n",
        "\n",
        "def fuzzy_matcher(header, standard_labels, threshold=80):\n",
        "    \"\"\"Match a header against standard labels using fuzzy matching.\"\"\"\n",
        "    header_norm = normalize_text(header)\n",
        "    best_score = 0\n",
        "    best_label = \"other\"\n",
        "    best_method = \"\"\n",
        "    best_jacc = 0\n",
        "\n",
        "    for label in standard_labels:\n",
        "        label_norm = normalize_text(label)\n",
        "        scores = {\n",
        "            \"ratio\": fuzz.ratio(header_norm, label_norm),\n",
        "            \"partial\": fuzz.partial_ratio(header_norm, label_norm),\n",
        "            \"token_sort\": fuzz.token_sort_ratio(header_norm, label_norm),\n",
        "            \"token_set\": fuzz.token_set_ratio(header_norm, label_norm),\n",
        "        }\n",
        "        jacc = token_jaccard(header_norm, label_norm)\n",
        "        len_avg = (len(header_norm) + len(label_norm)) / 2.0\n",
        "        if len_avg < 20:\n",
        "            combined = 0.6 * scores[\"ratio\"] + 0.4 * scores[\"partial\"]\n",
        "            method = \"ratio+partial\"\n",
        "        else:\n",
        "            combined = 0.6 * scores[\"token_set\"] + 0.25 * scores[\"token_sort\"] + 0.15 * scores[\"partial\"]\n",
        "            method = \"token_set/sort+partial\"\n",
        "            if scores[\"token_set\"] == 100 and jacc < 8:\n",
        "                combined = min(combined, 90)\n",
        "\n",
        "        if combined > best_score:\n",
        "            best_score = combined\n",
        "            best_label = label\n",
        "            best_method = method\n",
        "            best_jacc = jacc\n",
        "\n",
        "    return {\n",
        "        \"header\": header,\n",
        "        \"matched_label\": best_label if best_score >= threshold else \"other\",\n",
        "        \"score\": round(best_score, 2),\n",
        "        \"method\": best_method,\n",
        "        \"jaccard\": round(best_jacc, 2)\n",
        "    }"
      ],
      "metadata": {
        "id": "v5QEu1myxjPW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define scikit-learn transformers\n",
        "class ColumnClassifier(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Classify column headers using fuzzy matching.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.standard_labels = [\n",
        "            \"phone number\", \"citizenship number\", \"address\", \"municipality\", \"ward\", \"house number\",\n",
        "            \"tole\", \"name\", \"age\", \"gender\", \"family members\", \"demographics\", \"gps coordinates\",\n",
        "            \"latitude\", \"longitude\", \"ethnicity\", \"mother tongue\"\n",
        "        ]\n",
        "        self.column_classifications = {}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Classify columns and save to JSON.\"\"\"\n",
        "        self.column_classifications = {\n",
        "            col: fuzzy_matcher(col, self.standard_labels)[\"matched_label\"]\n",
        "            for col in X.columns\n",
        "        }\n",
        "        with open('column_classifications.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.column_classifications, f, indent=2, ensure_ascii=False)\n",
        "        print(\"Column classifications saved to 'column_classifications.json'\")\n",
        "        return X\n",
        "\n",
        "class PhoneValidator(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Validate phone numbers.\"\"\"\n",
        "    def __init__(self, phone_col='Phone number (फोन नं)'):\n",
        "        self.phone_col = phone_col\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Validate phone numbers and add validation columns.\"\"\"\n",
        "        if self.phone_col not in X.columns:\n",
        "            raise ValueError(f\"Column '{self.phone_col}' not found in dataset\")\n",
        "\n",
        "        def check_number(phone_str, default_region=\"NP\"):\n",
        "            try:\n",
        "                if phone_str is None:\n",
        "                    return {\"valid\": False, \"country\": None}\n",
        "                # Prepend +977 for Nepali numbers starting with 9\n",
        "                cleaned_phone = re.sub(r'[^0-9+]', '', str(phone_str))\n",
        "                if cleaned_phone and cleaned_phone.startswith('9') and not cleaned_phone.startswith('+'):\n",
        "                    cleaned_phone = f\"+977{cleaned_phone}\"\n",
        "                num = phonenumbers.parse(cleaned_phone, default_region)\n",
        "                if not phonenumbers.is_valid_number(num):\n",
        "                    return {\"valid\": False, \"country\": None}\n",
        "                country = geocoder.description_for_number(num, \"en\")\n",
        "                return {\"valid\": True, \"country\": country}\n",
        "            except Exception:\n",
        "                return {\"valid\": False, \"country\": None}\n",
        "\n",
        "        phone_results = X[self.phone_col].fill_null(\"\").map_elements(check_number, return_dtype=pl.Struct([pl.Field(\"valid\", pl.Boolean), pl.Field(\"country\", pl.Utf8)]))\n",
        "\n",
        "        X = X.with_columns([\n",
        "            phone_results.struct.field('valid').alias('phone_valid'),\n",
        "            phone_results.struct.field('country').alias('phone_country'),\n",
        "        ])\n",
        "\n",
        "        X = X.with_columns(\n",
        "            pl.when(pl.col('phone_valid'))\n",
        "            .then(\n",
        "                pl.when(pl.col('phone_country') == 'Nepal')\n",
        "                .then(pl.lit('nepali'))\n",
        "                .otherwise(pl.lit('international'))\n",
        "            )\n",
        "            .otherwise(pl.lit('invalid')).alias('phone_type')\n",
        "        )\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "class CitizenshipValidator(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Validate citizenship numbers.\"\"\"\n",
        "    def __init__(self, citizenship_col='Citizenship Number of House Owner (नागरिकता नं)'):\n",
        "        self.citizenship_col = citizenship_col\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Validate citizenship numbers and add validation columns.\"\"\"\n",
        "        if self.citizenship_col not in X.columns:\n",
        "            raise ValueError(f\"Column '{self.citizenship_col}' not found in dataset\")\n",
        "\n",
        "        def is_valid_citizenship(num):\n",
        "            if num is None or not isinstance(num, str) or num.strip() == '':\n",
        "                return {\"valid\": False, \"reason\": \"Empty or null\"}\n",
        "\n",
        "            num_normalized = num.replace('/', '-')\n",
        "\n",
        "            # Standard format: XX-XX-XX-XXXXX\n",
        "            if re.match(r'^\\d{1,2}-\\d{1,2}-\\d{2,3}-\\d{4,7}$', num_normalized):\n",
        "                parts = num_normalized.split('-')\n",
        "                district = int(parts[0])\n",
        "                year = int(parts[2])\n",
        "                if 1 <= district <= 77 and 0 <= year <= 82:\n",
        "                    return {\"valid\": True, \"reason\": \"Valid standard format\"}\n",
        "                return {\"valid\": False, \"reason\": f\"Invalid district or year: {district}, {year}\"}\n",
        "\n",
        "            # Simple / format: XXXX/XXX\n",
        "            if re.match(r'^\\d{4,8}/\\d{3,5}$', num):\n",
        "                parts = num.split('/')\n",
        "                year_str = parts[0][-2:] if len(parts[0]) > 2 else parts[0]\n",
        "                year = int(year_str)\n",
        "                if 0 <= year <= 82:\n",
        "                    return {\"valid\": True, \"reason\": \"Valid slash format\"}\n",
        "                return {\"valid\": False, \"reason\": f\"Invalid year: {year}\"}\n",
        "\n",
        "            # Plain digits: 10-12 long\n",
        "            if re.match(r'^\\d{10,12}$', num):\n",
        "                return {\"valid\": True, \"reason\": \"Valid plain digits\"}\n",
        "\n",
        "            return {\"valid\": False, \"reason\": \"Invalid format\"}\n",
        "\n",
        "        citizenship_results = X[self.citizenship_col].fill_null(\"\").map_elements(is_valid_citizenship, return_dtype=pl.Struct([pl.Field(\"valid\", pl.Boolean), pl.Field(\"reason\", pl.Utf8)]))\n",
        "\n",
        "        X = X.with_columns([\n",
        "            citizenship_results.struct.field('valid').alias('citizenship_valid'),\n",
        "            citizenship_results.struct.field('reason').alias('citizenship_reason')\n",
        "        ])\n",
        "        return X"
      ],
      "metadata": {
        "id": "qBiarK6axwLH"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define scikit-learn pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('column_classifier', ColumnClassifier()),\n",
        "    ('phone_validator', PhoneValidator(phone_col='Phone number (फोन नं)')),\n",
        "    ('citizenship_validator', CitizenshipValidator(citizenship_col='Citizenship Number of House Owner (नागरिकता नं)'))\n",
        "])\n"
      ],
      "metadata": {
        "id": "8_h7hhmix81u"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Process dataset\n",
        "def process_dataset(input_path):\n",
        "    \"\"\"Process the dataset using the pipeline and split into valid/invalid CSVs.\"\"\"\n",
        "    # Load dataset\n",
        "    df = pl.read_csv(input_path)\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "    print(\"Dataset head:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Apply pipeline\n",
        "    df_transformed = pipeline.fit_transform(df)\n",
        "\n",
        "    # Define output columns\n",
        "    output_cols = [\n",
        "        'Phone number (फोन नं)', 'phone_valid', 'phone_type', 'phone_country',\n",
        "        'Citizenship Number of House Owner (नागरिकता नं)', 'citizenship_valid', 'citizenship_reason'\n",
        "    ]\n",
        "\n",
        "    # Split into valid and invalid data\n",
        "    valid_df = df_transformed.filter(\n",
        "        (pl.col('phone_valid') == True) &\n",
        "        (pl.col('citizenship_valid') == True)\n",
        "    ).select(output_cols)\n",
        "    invalid_df = df_transformed.filter(\n",
        "        ~((pl.col('phone_valid') == True) &\n",
        "          (pl.col('citizenship_valid') == True))\n",
        "    ).select(output_cols)\n",
        "\n",
        "    # Save CSVs\n",
        "    valid_df.write_csv('valid_rahat_data.csv')\n",
        "    invalid_df.write_csv('invalid_rahat_data.csv')\n",
        "    print(\"Valid data saved as 'valid_rahat_data.csv'\")\n",
        "    print(\"Invalid data saved as 'invalid_rahat_data.csv'\")\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\nValidation Summary:\")\n",
        "    print(f\"Total rows: {df_transformed.height}\")\n",
        "    print(f\"Valid phone numbers: {df_transformed['phone_valid'].sum()}\")\n",
        "    print(f\"Nepali phones: {df_transformed.filter(pl.col('phone_type') == 'nepali').height}\")\n",
        "    print(f\"International phones: {df_transformed.filter(pl.col('phone_type') == 'international').height}\")\n",
        "    print(f\"Invalid phones: {df_transformed.height - df_transformed['phone_valid'].sum()}\")\n",
        "    print(f\"Valid citizenship numbers: {df_transformed['citizenship_valid'].sum()}\")\n",
        "    print(f\"Invalid or empty citizenships: {df_transformed.height - df_transformed['citizenship_valid'].sum()}\")\n",
        "    print(f\"Valid rows (both phone and citizenship valid): {valid_df.height}\")\n",
        "    print(f\"Invalid rows (either phone or citizenship invalid): {invalid_df.height}\")\n",
        "\n",
        "    # Generate chart for validation results\n",
        "    chart_config = {\n",
        "        \"type\": \"bar\",\n",
        "        \"data\": {\n",
        "            \"labels\": [\"Valid Phones\", \"Invalid Phones\", \"Valid Citizenships\", \"Invalid Citizenships\", \"Valid Rows\", \"Invalid Rows\"],\n",
        "            \"datasets\": [{\n",
        "                \"label\": \"Validation Counts\",\n",
        "                \"data\": [\n",
        "                    df_transformed['phone_valid'].sum(),\n",
        "                    df_transformed.height - df_transformed['phone_valid'].sum(),\n",
        "                    df_transformed['citizenship_valid'].sum(),\n",
        "                    df_transformed.height - df_transformed['citizenship_valid'].sum(),\n",
        "                    valid_df.height,\n",
        "                    invalid_df.height\n",
        "                ],\n",
        "                \"backgroundColor\": [\"#36A2EB\", \"#FF6384\", \"#90EE90\", \"#FFCE56\", \"#4BC0C0\", \"#9966FF\"],\n",
        "                \"borderColor\": [\"#36A2EB\", \"#FF6384\", \"#90EE90\", \"#FFCE56\", \"#4BC0C0\", \"#9966FF\"],\n",
        "                \"borderWidth\": 1\n",
        "            }]\n",
        "        },\n",
        "        \"options\": {\n",
        "            \"scales\": {\n",
        "                \"y\": {\"beginAtZero\": True, \"title\": {\"display\": True, \"text\": \"Count\"}},\n",
        "                \"x\": {\"title\": {\"display\": True, \"text\": \"Validation Status\"}}\n",
        "            },\n",
        "            \"plugins\": {\"title\": {\"display\": True, \"text\": \"Phone and Citizenship Validation Results\"}}\n",
        "        }\n",
        "    }\n",
        "    with open('validation_chart.json', 'w') as f:\n",
        "        json.dump(chart_config, f, indent=2)\n",
        "    print(\"Chart configuration saved to 'validation_chart.json'\")\n",
        "\n",
        "    return df_transformed"
      ],
      "metadata": {
        "id": "N7CBN5-qyBb0"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Execute\n",
        "input_path = 'first_100_rows (1) - first_100_rows (1).csv.csv'  # Provided filename\n",
        "try:\n",
        "    df = process_dataset(input_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Input file '{input_path}' not found. Please provide the correct path.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K733s62yHey",
        "outputId": "a70f167d-429e-4c93-8a1c-348d2baf6acf"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (100, 353)\n",
            "Dataset head:\n",
            "shape: (5, 353)\n",
            "┌─────┬─────────────┬─────────────┬────────────┬───┬────────┬────────────┬────────────┬────────────┐\n",
            "│     ┆ start       ┆ end         ┆ today      ┆ … ┆ घरबाट  ┆ (घरबाट     ┆ (नजिकैको    ┆ (Distance  │\n",
            "│ --- ┆ ---         ┆ ---         ┆ ---        ┆   ┆ स्वास्थ्य ┆ बजारको दुरी ┆ शौचालय र   ┆ to safe    │\n",
            "│ i64 ┆ str         ┆ str         ┆ str        ┆   ┆ संस्थाको ┆ in METER   ┆ घरको दुरी   ┆ Shelter in │\n",
            "│     ┆             ┆             ┆            ┆   ┆ दुरी …  ┆ ---        ┆ in…        ┆ M…         │\n",
            "│     ┆             ┆             ┆            ┆   ┆ ---    ┆ i64        ┆ ---        ┆ ---        │\n",
            "│     ┆             ┆             ┆            ┆   ┆ i64    ┆            ┆ str        ┆ i64        │\n",
            "╞═════╪═════════════╪═════════════╪════════════╪═══╪════════╪════════════╪════════════╪════════════╡\n",
            "│ 0   ┆ 2022-04-13T ┆ 2022-04-13T ┆ 2022-04-13 ┆ … ┆ 2      ┆ 100        ┆ null       ┆ 100        │\n",
            "│     ┆ 10:14:57.94 ┆ 10:49:51.21 ┆            ┆   ┆        ┆            ┆            ┆            │\n",
            "│     ┆ 6+05:45     ┆ 3+05:45     ┆            ┆   ┆        ┆            ┆            ┆            │\n",
            "│ 1   ┆ 2022-04-13T ┆ 2022-04-13T ┆ 2022-04-13 ┆ … ┆ 1      ┆ 2          ┆ null       ┆ null       │\n",
            "│     ┆ 10:22:34.31 ┆ 11:12:32.12 ┆            ┆   ┆        ┆            ┆            ┆            │\n",
            "│     ┆ 2+05:45     ┆ 8+05:45     ┆            ┆   ┆        ┆            ┆            ┆            │\n",
            "│ 2   ┆ 2022-04-13T ┆ 2022-04-13T ┆ 2022-04-13 ┆ … ┆ 1      ┆ 2          ┆ null       ┆ null       │\n",
            "│     ┆ 13:17:31.59 ┆ 14:26:29.91 ┆            ┆   ┆        ┆            ┆            ┆            │\n",
            "│     ┆ 6+05:45     ┆ 2+05:45     ┆            ┆   ┆        ┆            ┆            ┆            │\n",
            "│ 3   ┆ 2022-04-13T ┆ 2022-04-13T ┆ 2022-04-13 ┆ … ┆ 500    ┆ 3          ┆ null       ┆ null       │\n",
            "│     ┆ 12:25:30.70 ┆ 15:43:43.01 ┆            ┆   ┆        ┆            ┆            ┆            │\n",
            "│     ┆ 3+05:45     ┆ 6+05:45     ┆            ┆   ┆        ┆            ┆            ┆            │\n",
            "│ 4   ┆ 2022-04-13T ┆ 2022-04-13T ┆ 2022-04-13 ┆ … ┆ 500    ┆ 3          ┆ null       ┆ null       │\n",
            "│     ┆ 13:56:25.89 ┆ 15:44:52.11 ┆            ┆   ┆        ┆            ┆            ┆            │\n",
            "│     ┆ 5+05:45     ┆ 4+05:45     ┆            ┆   ┆        ┆            ┆            ┆            │\n",
            "└─────┴─────────────┴─────────────┴────────────┴───┴────────┴────────────┴────────────┴────────────┘\n",
            "Column classifications saved to 'column_classifications.json'\n",
            "Valid data saved as 'valid_rahat_data.csv'\n",
            "Invalid data saved as 'invalid_rahat_data.csv'\n",
            "\n",
            "Validation Summary:\n",
            "Total rows: 100\n",
            "Valid phone numbers: 84\n",
            "Nepali phones: 84\n",
            "International phones: 0\n",
            "Invalid phones: 16\n",
            "Valid citizenship numbers: 23\n",
            "Invalid or empty citizenships: 77\n",
            "Valid rows (both phone and citizenship valid): 22\n",
            "Invalid rows (either phone or citizenship invalid): 78\n",
            "Chart configuration saved to 'validation_chart.json'\n"
          ]
        }
      ]
    }
  ]
}